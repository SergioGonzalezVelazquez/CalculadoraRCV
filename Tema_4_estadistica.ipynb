{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tema 4 estadistica.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergioGonzalezVelazquez/CalculadoraRCV/blob/master/Tema_4_estadistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcQ_OiILJp1p"
      },
      "source": [
        "# Tema 4. Introducción al aprendizaje supervisado\n",
        "\n",
        "En este tema se verán algunos conceptos básicos relativos al aprendizaje supervisado, que está indicado en la modelización de una __variable respuesta__ $Y$ (explicativa, _output_ o resultado) a través de múltiples variables explicativas $X_1, X_2, ..., X_p$ (predictores, características o _input_). A lo largo de este tema se verá que, dentro del análisis supervisado, lo que determina el modelo a utilizar es la naturaleza de la variable respuesta.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q-hxd06fWSC"
      },
      "source": [
        "## Introducción\n",
        "---\n",
        "\n",
        "### Tipos de modelos \n",
        "\n",
        "Según la naturaleza de la variable respuestas, los principales modelos del análisis supervisado son:\n",
        "\n",
        "-  $Y$ __dicotómica__: regresión logística / análisis discriminante\n",
        "-  $Y$ __continua__: regresión lineal\n",
        "- $Y$ __nominal__: regresión logística politómica / análisis discriminante politómico.\n",
        "- $Y$ __ordinal__: regresión de riesgo de proporcionales (_odds proportional regression_).\n",
        "\n",
        "\n",
        "Por otro lado, los principales modelos de análisis supervisado se suelen enumerar según la dicotomía:\n",
        "\n",
        "- __Regresión__: en el caso de que la variable repuesta sea continua.\n",
        "- __Clasificación:__ en el caso de que la variable respuesta sea nominal.\n",
        "\n",
        " \n",
        "\n",
        "### Codificación de las variables explicativas\n",
        "\n",
        "La codificación de las variables explicativas para que formen parte de los modelos se hace de la forma siguiente:\n",
        "\n",
        "- Si son continuas, no es necesario hacer ninguna codificación. Se introducen en el modelo directamente con sus valores numéricos.\n",
        "\n",
        "- Si son nominales con *k* categorías, es necesario crear $k - 1$ variables ficticias (*dummy*). Existen varias formas de crear dichas variables. Uno de los métodos, es el dado en la siguiente tabla.\n",
        "\n",
        "| Variable nominal | Dummy_2 | Dummy_3 | ... | Dummy_k |\n",
        "|------------------|---------|---------|-----|---------|\n",
        "| Nivel 1          | 0       | 0       | ... |         |\n",
        "| Nivel 2          | 1       | 0       | ... |         |\n",
        "| Nivel 3          | 0       | 1       | ... |         |\n",
        "| ...              | ...     | ...     | ... |         |\n",
        "| Nivel k          | 0       | 0       | ... |         |\n",
        "\n",
        "- Si son ordinales, una posibilidad es tratarlas como nominales, pero se estaría perdiendo información. Sin embargo, lo más adecuado sería transformaciones ortogonales. No sería correcto introducirlas como si fueran continuas con valores numéricos asociados a los niveles ordenados. \n",
        "\n",
        "A menudo, también se suelen considerar transformaciones de variables explicativas e interacciones entre variables explicativas que se codifican como el producto de éstas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfQsFjFHKXdd"
      },
      "source": [
        "## ¿Qué es el Aprendizaje Supervisado?\n",
        "---\n",
        "\n",
        "\n",
        "Imaginemos que somos una consultora estadística, y un cliente nos ha contratado para que le asesoremos sobre cómo mejorar las ventas de un determinado producto. Nos proporciona un *dataset* **_Advertising_** con las ventas de dicho producto en 200 mercados diferentes, junto con el presupuesto destinado a publicidad en cada uno de estos mercados para tres medios de comunicación: **TV**, **radio** y **periódico**. En la siguiente figura se respresenta gráficamente los datos de este *dataset*, utilizando miles de unidades como médida de las ventas y miles de dólares para el presupuesto destinado a cada uno de los medios de comunicación. La línea azul representa un simple modelo que se podría utiliar para predecir el número de ventas en función del presupuesto en publicidad. \n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/c7706202939737f4b10d00b2d2818ab3.png\" width=\"100%\"/>\n",
        "<figcaption>Fig.1 - El dataset Advertising </figcaption>\n",
        "\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "\n",
        "Si somos capaces de encontrar una relación entre la publicidad y las ventas, podremos aconsejar al cliente para que incremente sus ventas ajustando el presupuesto que destina a publicidad.  En otras palabras, nuestro objetivo es desarollar un modelo preciso que se utilice para hacer predicciones de ventas a partir de los datos de entrada.\n",
        "\n",
        "En este contexto, los datos sobre el presupuesto serían las **variables de entrada**, mientras que el número de ventas son la **variable salida**. Las variables de entrada se denotan con el símbolo $X$, con un subíndice para distinguir cada una de ellas. Por ejemplo, $X_1$ es el prespuesto destinado a TV, $X_2$ el prespuesto de radio y $X_3$ el presupuesto de periódico. La variable de salida, o variable dependiente, se denota con el símbolo $Y$. \n",
        "\n",
        "\n",
        "De manera más genérica, la mayoría de los modelos establecen una relación de $Y$ en términos de $X = (X_1, X_2, ..., X_p)$ a través de una ecuación del tipo:\n",
        "\n",
        "$$Y = f(X_1, X_2, ..., X_p) + \\varepsilon = f(X) + \\varepsilon$$\n",
        "\n",
        "donde $f$ es una función fija pero desconocida, que representa la información sistemática de las variables explicativas, y $\\varepsilon$ es una v.a. independiente de $X$ con $E[\\varepsilon]=0$, que representa una perturbación de la información sistemática de X.\n",
        "\n",
        "Donde $f$ es una función desconocida de $X_1, ..., X_p$, y \n",
        "$\\varepsilon$ es un término de error, independiente de $X$ y con media cero. En esta fórmula, $f$ representa la información sistemática que X proporciona sobre Y.\n",
        "\n",
        "El objetivo es determinar $\\hat{f}$ para estimar $f$ y poder predecir $Y$ a través de $\\hat{Y} = \\hat{f}(X)$. En esencia, el aprendizaje estadístico hace referencia a un conjunto de técnicas que permite estimar $f$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF_H27P3q0qi"
      },
      "source": [
        "### ¿Por qué estimar $f$?\n",
        "\n",
        "Hay dos motivos principales para estimar $f$, la **predicción** y la **inferencia**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAj-69Bv90Gd"
      },
      "source": [
        "#### Predicción\n",
        "En muchas situaciones, no es sencillo obtener la salida $Y$ a partir de las entradas $X$. En estos casos, dado que el término de error promedia 0, el objetivo es determinar $\\hat{f}$ para estimar $f$ y poder predecir $\\hat{Y}$ a través de:\n",
        "\n",
        "$$\\hat{Y} = \\hat{f}(X)$$\n",
        "\n",
        "donde $\\hat{f}$ representa nuestra estimación para $\\hat{f}$ y $\\hat{Y}$ el resultado de predecir Y. En este contexto, $\\hat{f}$ se considera como una caja negra, en el sentido de que no nos tenemos que preocupar por la forma de $\\hat{f}$ si da como resultado predicciones precisas para $Y$.\n",
        "\n",
        "Una medida del error que se comete cuando se utiliza el modelo estimado es:\n",
        "\n",
        "$$E[Y - \\hat{Y}]^{2}$$\n",
        "\n",
        "Esta medida del error se puede descomponer de forma que aparezcan dos sumandos, según se detalla a continuación:\n",
        "\n",
        "$$E[Y - \\hat{Y}]^{2} = E[f(X) + \\varepsilon - \\hat{f}(X)]^{2} = (f(X) - \\hat{f}(X))^{2} + V[\\varepsilon]$$\n",
        "\n",
        "El primer sumando de dicha descomposición se denomina **error reducible**, y el segundo, **error irreducible**, ya que aunque se llegue a estimar $f$ de forma perfecta, siempre existará el error debido a la perturbación de $\\varepsilon$.\n",
        "\n",
        "El objetivo del libro es mostrar técnicas para estimar $f$ con la idea de minimizar el error reducible. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOHGlOr8q-wj"
      },
      "source": [
        "\n",
        "#### Inferencia\n",
        "\n",
        "A menudo nos interesa comprender la forma en que $Y$ se ve afectado cuando $X_1, ..., X_p$ cambia. En esta situación, deseamos estimar $f$, pero nuestro objetivo no es necesariamente hacer predicciones para $Y$. En su lugar, queremos comprender la relación entre $X$ e $Y$, o más específicamente, comprender cómo cambia $Y$ en función de $X_1, .. ., X_p$. \n",
        "\n",
        "En este escenario, estamos interesados en responder a las siguientes preguntas:\n",
        "\n",
        "- ***¿Qué predictores están asociados con la respuesta?*** A menudo se da el caso de que sólo una pequeña fracción de los predictores disponibles están sustancialmente asociados con $Y$. La identificación de los pocos predictores importantes puede ser extremadamente útil.\n",
        "\n",
        "- ***¿Qué relaciones existe entre la variable respuesta y cada variable predictora?*** Algunos predictores pueden tener una relación positiva con $Y$, en el sentido de que aumentar el predictor está asociado con valores crecientes de $Y$. Otros predictores pueden tener la relación opuesta. Dependiendo de la complejidad, la relación entre la respuesta y un predictor dado también puede depender de los valores de los otros predictores.\n",
        "\n",
        "- ***¿Se puede explicar de manera adecuada la relación entre Y y cada uno de los pronosticadores usando una ecuación lineal, o la relación es más compleja?*** Comúnmente, la mayoría de los métodos para estimar $f$ han adoptado una forma lineal. En algunas situaciones, tal suposición es razonable o incluso deseable. Pero a menudo la verdadera relación es más complicada, y un modelo lineal no puede proporcionar una representación precisa de la relación entre las variables de entrada y salida.\n",
        "\n",
        "Por ejemplo, considere una empresa que esté interesada en realizar una campaña de marketing directo. El objetivo es identificar a las personas que responderán positivamente a un correo, basándose en las observaciones de las variables demográficas medidas en cada individuo. En este caso, las variables demográficas sirven como predictores y la respuesta a la campaña de marketing (ya sea positiva o negativa) sirve como resultado. La empresa no está interesada en obtener una comprensión profunda de las relaciones entre cada predictor individual y la respuesta; en cambio, la empresa simplemente quiere un modelo preciso para predecir la respuesta utilizando los predictores. Este es un ejemplo de modelado para predicción.\n",
        "\n",
        "Por el contrario, considerese los datos de **Advertising** puestos anteriormente. Uno puede estar interesado en responder preguntas como: *¿Qué medios contribuyen a las ventas?*, *¿Qué medios generan el mayor impulso en las ventas?* o *¿Cuánto aumento en las ventas está asociado con un dado un aumento en la publicidad televisiva?* Esta situación cae en el paradigma de inferencia. \n",
        "\n",
        "**Dependiendo de si nuestro objetivo final es la predicción, la inferencia o una combinación de los dos, pueden ser apropiados diferentes métodos para estimar $f$**.  Por ejemplo, los modelos lineales permiten una inferencia relativamente simple e interpretable, pero pueden no producir predicciones tan precisas como algunos otros enfoques. En contraste, algunos de los enfoques altamente no lineales que discutimos en los últimos capítulos de este libro pueden potencialmente proporcionar predicciones bastante precisas para $Y$, pero esto se produce a expensas de un modelo menos interpretable para el que la inferencia es más desafiante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtk44T3yqugg"
      },
      "source": [
        "### ¿Cómo estimar $f$?\n",
        "\n",
        "Tanto las aproximaciones lineales como las no lineales para estimar $f$ tienen algunas características comunes. En esta sección se van a comentar esas características. Asumiremos en todo momento que hemos observado un conjunto de datos con $n$ puntos diferentes. Por ejemplo en la siguiente imagen se representan $n=30$ puntos. Estas observaciones se denominan **conjunto de entrenamiento**, porque las usaremos para entrenar o enseñar a nuestro método cómo estimar $f$. \n",
        "\n",
        "\n",
        "Sea $x_{ij}$ el valor del j-ésimo predictor, o entrada, para la observación $i$, donde $i = 1,2, ..., n$ y $j = 1,2, ..., p$. En consecuencia, sea $y_i$ la variable de respuesta para la i-ésima observación. Entonces, nuestros datos de entrenamiento consisten en $\\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\\}$ donde $x_i = (x_i1, x_i2, ..., x_ip)^T$.\n",
        "\n",
        "Nuestro objetivo es aplicar un modelo de aprendizaje estadístico a los datos de entrenamiento para estimar la función desconocida $f$. En otras palabras, queremos encontrar una función $\\hat{f}$ tal que $Y ≈ \\hat{f}(X)$ para cualquier observación $(X, Y)$. En general, la mayoría de los métodos de aprendizaje estadístico pueden caracterizarse como **paramétrico** o no **paramétrico**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-0R0NJk-C20"
      },
      "source": [
        "#### Modelos paramétricos\n",
        "\n",
        "Los métodos paramétricos implican un enfoque basado en modelos de dos pasos\n",
        "\n",
        "  1. Primero, hacemos una suposición sobre la forma funcional, o forma, de $f$. Por ejemplo, una suposición muy simple es que $f$ es lineal en $X$:\n",
        "\n",
        "  $$ f(X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p $$\n",
        "\n",
        "  Una vez que asumimos que $f$ es lineal, el problema de estimar $f$ se simplifica enormemente. En lugar de tener que estimar una función p-dimensional completamente arbitraria $f(X)$, solo se necesita estimar $p + 1$ coeficientes $\\beta_0, \\beta_1, ..., \\beta_p$.\n",
        "\n",
        "  2. Una vez que se ha seleccionado un modelo, necesitamos un procedimiento que utilice los datos de entrenamiento para **ajustar** o **entrenar** el modelo.  En el caso del modelo lineal, necesitamos estimar los parámetros $\\beta_0, \\beta_1, ..., \\beta_p$. Es decir, queremos encontrar valores de estos parámetros tales que:\n",
        "\n",
        "  $$ Y \\approx \\beta_0 + \\beta_1 X_1 + \\beta_1 X_2 + ... + \\beta_p X_p $$\n",
        "\n",
        "Por ejemplo, supongamos que tenemos los siguientes datos:\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/f752cec4809f9f04ac890cc09be691e6.png\" width=\"70%\"/>\n",
        "<figcaption>Fig.2 </figcaption>\n",
        "\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La Figura 2.4, muestra un ejemplo de enfoque paramétrico para  asumir una relación lineal y ajustar un modelo de la forma:\n",
        "$$ income \\approx \\beta_0 + \\beta_1 education + \\beta_1 seniority $$\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/5721db45d11f0f5fa9d573ebb4190206.png\" width=\"50%\"/>\n",
        "<figcaption>Fig.3 </figcaption>\n",
        "\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "El enfoque basado en modelos que se acaba de describir se denomina paramétrico; reduce el problema de estimar $f$ a uno de estimar un conjunto de parámetros. Asumir una forma paramétrica para $f$ simplifica el problema de estimar $f$ porque generalmente es mucho más fácil estimar un conjunto de parámetros, como $\\beta_0, \\beta_1, ..., \\beta_p$ en el modelo lineal, que ajustar un función arbitraria $f$. La posible desventaja de un enfoque paramétrico es que el modelo que elegimos generalmente no coincidirá con la verdadera forma desconocida de $f$. Si el modelo elegido está demasiado lejos de la verdadera $f$, la estimación nour será mala. Podemos intentar abordar este problema eligiendo modelos *flexibles* que puedan adaptarse a muchas formas funcionales posibles diferentes para $f$. Pero, en general, ajustar un modelo más flexible requiere estimar un número mayor de parámetros. Estos modelos más complejos pueden dar lugar a un fenómeno conocido como sobreajuste de los datos, lo que esencialmente significa que siguen los errores o el ruido demasiado de cerca.\n",
        "\n",
        "En los modelos es habitual, cuando $f$ es paramétrica, teber que estimar los parámetros o coeficientes del modelo, de forma puntual y a través de sus intervalos de confianza. Los coeficientes del modelo dan una una medida del efecto de cada variable, aunque en algunas ocasiones hay que transformarlos, como en la regresión logística.\n",
        "\n",
        "La estimación de los parámetros se suele hacer a través de distintos métodos, como el de **mínimos cuadrados** o **máxima verosimilitud**. El proceso de cosntrucción de un modelo tiene que seguirse a través de una estrategia\n",
        "de modelización (*model building*) en el que bien de forma manual o de forma automática se seleccione un modelo candidato que habría que evaluar si se comporta de manera razonable. En este proceso hay que dividir la muestra de forma aleatoria en un **conjunto de datos de entrenamiento** (con el que se construye el modelo candidato) y un **conjunto de datos de validación** (con el que se evalúa su rendimiento).\n",
        "\n",
        "En los modelos con variable respuesta continua es habitual utilizar el error cuadrático medio (*mean square error*) en el conjunto de entrenamiento como medida del rendimiento del modelo. Cuando la variable respuesta\n",
        "es dicotómica se utilizan la sensibilidad, la especificidad y la curva roc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XFT9OxdSu4h"
      },
      "source": [
        "#### Modelos no paramétricos \n",
        "\n",
        "Los métodos no paramétricos no hacen suposiciones explícitas sobre la forma funcional de $f$. En su lugar, buscan una estimación de $f$ que se acerque lo más posible a los puntos de datos sin ser demasiado tosco o ondulado. Tales enfoques pueden tener una gran ventaja sobre los enfoques paramétricos: al evitar la suposición de una forma funcional particular para $f$, tienen el potencial de ajustarse con precisión a un abanico más amplio de formas posibles para $f$. Cualquier enfoque paramétrico trae consigo la posibilidad de que la forma funcional utilizada para estimar $f$ sea muy diferente de la verdadera $f$, en cuyo caso el modelo resultante no se ajustará bien a los datos. Por el contrario, los enfoques no paramétricos evitan completamente este peligro, ya que esencialmente no se hace ninguna suposición sobre la forma de $f$. Pero los enfoques no paramétricos adolecen de una gran desventaja: dado que no reducen el problema de estimar $f$ a un número pequeño de parámetros, se requiere un número muy grande de observaciones (normalmente se necesita mucho más para un enfoque paramétrico) en para obtener una estimación precisa de $f$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae1BzBddVRAD"
      },
      "source": [
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/02962255734ad83ef2cb3ef0c289c267.png\" width=\"45%\"/>\n",
        "  <figcaption>Fig.4 - </figcaption>\n",
        "\n",
        "<img src=\"https://i.gyazo.com/4f59cd390d787a79cc073b0e8921dc5e.png\" width=\"45%\"/>\n",
        "  <figcaption>Fig.5 - </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "En la Figura 4 se muestra un ejemplo de un enfoque no paramétrico para ajustar los datos de **Income**. Se usa una *thin-plate spline* para estimar $f$. Este enfoque no impone ningún modelo preespecificado en $f$. En su lugar, intenta producir una estimación de $f$ que sea lo más cercana posible a los datos observados, sujeto al ajuste, es decir, la superficie amarilla en Figura 4. \n",
        "\n",
        "La Figura 5 muestra el mismo ajuste *thin-plate spline* con un nivel más bajo de suavidad, lo que permite un ajuste más tosco. ¡La estimación resultante se ajusta perfectamente a los datos observados! Sin embargo, el ajuste de spline que se muestra en la Figura 5 es mucho más variable que la verdadera función $f$. Este es un ejemplo de sobreajuste de los datos, que discutimos anteriormente. Es una situación indeseable porque el ajuste obtenido no producirá estimaciones precisas de la respuesta en nuevas observaciones que no formaban parte del conjunto de datos de entrenamiento original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XvZjEcJqJFB"
      },
      "source": [
        "### El equilibro entre la precisión de la predicción y la interpretación del modelo.\n",
        "\n",
        "Algunos de las técnicas que veremos son más flexibles, o más restrictivas, en el sentido de que pueden producir solo un pequeño abanico de formas para estimar $f$. Por ejemplo, la regresión lineal es un enfoque inflexible porque solo genera funciones lineales como las mostradas en la Fig.3. Otras técnicas, como las mostradas en las Fig.4 y Fig.5, se consideran más flexibles porque son capaces de generar un rango más amplio de posibles formas para estimar $f$.\n",
        "\n",
        "Existen varios motivos por los que es preferible seleccionar un modelo más restrictivo, en especial, en los problemas de regresión, ya que los modelos restrictivos son mucho más interpretable.  Por ejemplo, para un problema de regresión un modelo lineal puede ser una buena elección porque será bastante fácil de entender la relación entre $Y$ y $X_1, X_2, ..., X_p$. En cambio, los enfoques muy flexibles, pueden llevarnos a estimaciones tan complejas de $f$ que sería difícil entender cómo cualquier predictor individual está asociado con la variable respuesta.\n",
        "\n",
        "La Fig.6 muestra gráficamente el dilema entre la flexibilidad y la interpretación para algunas de las técnicas que estudiaremos. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/b3bf21f19444ed46613bf4528972b33a.png\" width=\"60%\"/>\n",
        "<figcaption>Fig.6 </figcaption>\n",
        "\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv9inchnqmA4"
      },
      "source": [
        "### Aprendizaje supervisado vs. aprendizaje no supervisado\n",
        "\n",
        "La mayoría de los problemas de aprendizaje estadístico se enmarcan en una de estas dos categorías: supervisados o no supervisados.  En los problemas **supervisados**, para cada observación de las variables predictoras $x_i, i= 1, ..., n$, existe una medida $y_i$ asociada. Nuestro objetivo en estos casos es ajustar un modelo que refleje la respuesta a las variables predictoras, de forma que podamos predecir de manera precisa la salida para entradas futuras. \n",
        "\n",
        "Por el contrario, en el aprendizaje **no supervisado** no contamos con la salida $y_i$ asociada al vector de observaciones $x_i$. Por tanto, no es posible ajustar un modelo de regresión lineal, porque no hay una variable respuesta que predecir. En este contexto, nuestro objetivo es intentar descubrir las relaciones entre las variables o entre las observaciones. Por ejemplo, una técnica de aprendizaje no supervisado es el agrupamiento (*clustering*), cuyo objetivo es determinar como $x1, ..., xn$ se agrupan en distintos grupos. \n",
        "\n",
        "La Fig 2.7 muestra un simple ejemplo de un problema de *clustering*. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/16f2e18fedfe339895b99e7966a38011.png\" width=\"60%\"/>\n",
        "<figcaption>Fig.7 </figcaption>\n",
        "\n",
        "</p>\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLOHbxqGqvR-"
      },
      "source": [
        "### Problemas de clasificación vs. problemas de regresión\n",
        "\n",
        "Las variables se pueden clasificar como **cualitativas** (categóricas), si sólo pueden tomar un conjunto limitado de *k* clases, o categorías (por ejemplo, el género de una persona);  y  **cuantitativas**, si solo toman valores numéricos (edad de una persona o el precio de una casa). \n",
        "\n",
        "Generalmente, los problemas en los que la variable salida es cuantitativa se conocen como **problemas de regresión**, mientras que, si la variable salida es cualitativa, estamos antes **problemas de clasificación**.  \n",
        "\n",
        " Por ejemplo, la regresión lineal de los mínimos cuadrados se utiliza con una respuesta cuantitativa, mientras que la regresión logística se utiliza típicamente con una salida cualitativa (de dos clases, o binario). Como tal, se utiliza a menudo como método de clasificación.\n",
        "\n",
        "Otras técnicas estadísticas, como KNN o *boosting* se pueden utilizar tanto con variables respuesta cualitativas como cuantitativas.\n",
        "\n",
        "En definitiva, generalmente, la técnica estadística a utilizar se selecciona en base a la naturaleza (cualitativa o cuantitativa) de la variable salida $Y$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgd_JEn7KeS-"
      },
      "source": [
        "## Evaluación de la precisión del modelo\n",
        "---\n",
        "\n",
        "Ningún método domina a todos los demás sobre todos los conjuntos de datos posibles. En un conjunto de datos en particular, un método específico puede funcionar mejor, pero algún otro método puede funcionar mejor en un conjunto de datos similar pero diferente. Por tanto, es una tarea importante decidir para cualquier conjunto de datos determinado qué método produce los mejores resultados. Seleccionar el mejor enfoque puede ser una de las partes más desafiantes de realizar el aprendizaje estadístico en la práctica. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRPnF1hx-uJN"
      },
      "source": [
        "### Medir el rendimiento del modelo\n",
        "\n",
        "Para evaluar el rendimiento de un modelo en un conjunto de datos determina, se necesita una forma de medir cómo de buenas son sus preducciones en relación con los valores realmente observados. Es decir, necesitamos cuantificar la medida en que el valor de respuesta predicho para una observación determinada se acerca al valor de respuesta real para esa observación. \n",
        "\n",
        "En los problemas de regresión, la medida más utilizada es el **error cuadrático medio** (*mean squared error*, MSE), dado por \n",
        "\n",
        "$$ MSE = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{f}(x_i))^2 $$\n",
        "\n",
        "donde $\\hat{f}(x_i)$ es la predicción que $\\hat{f}$ da para la i-ésima observación. El $MSE$ será pequeño si las respuestas predichas están muy cerca de las respuestas verdaderas, y será grande si para algunas de las observaciones, las respuestas predichas y verdaderas difieren sustancialmente.\n",
        "\n",
        "El MSE se calcula utilizando los datos de entrenamiento que se usaron para ajustar el modelo, por lo que debería denominarse con mayor precisión el *MSE de entrenamiento*. Pero en general, realmente no nos importa qué tan bien funciona el método con los datos de entrenamiento. Más bien, nos interesa la precisión de las predicciones que obtenemos cuando aplicamos nuestro método a datos que no se han visto previamente. \n",
        "\n",
        "Para expresarlo más matemáticamente, suponga que ajustamos nuestro método de aprendizaje estadístico a nuestras observaciones de entrenamiento $\\{(x1, y1), (x2, y2), ..., (xn, yn)\\}$, y obtenemos la estimación $\\hat{f}$. Entonces podemos calcular $\\hat{f}(x_1), \\hat{f}(x_2), ..., \\hat{f}(x_n)$. Si estos son aproximadamente iguales a $y_1, y_2, ..., y_n$, entonces el $MSE$ de entrenamiento dado por (2.5) es pequeño. Sin embargo, realmente no estamos interesados en si $\\hat{f}(x_i) ≈ y_i$; en su lugar, queremos saber si $f(x_0)$ es aproximadamente igual a $y_0$, donde $(x_0, y_0)$ es una observación de prueba nunca antes vista que no se utiliza para entrenar el método de aprendizaje estadístico. Queremos elegir el método que dé el $MSE$ de prueba más bajo, en contraposición al $MSE$ de entrenamiento más bajo. En otras palabras, si tuviéramos una gran cantidad de observaciones de prueba, podríamos calcular el error de predicción cuadrático promedio para estas observaciones de prueba $(x_0, y_0)$. Nos gustaría seleccionar el modelo para el cual el promedio de esta cantidad, la prueba $MSE$: es lo más pequeño posible.\n",
        "\n",
        "$$ Ave(y_0 - \\hat{f}(x_0))^2 $$\n",
        "\n",
        "En algunos entornos, podemos tener un conjunto de datos de prueba disponible, es decir, podemos tener acceso a un conjunto de observaciones que no se utilizaron para entrenar el método de aprendizaje estadístico. Luego, podemos simplemente evaluar (Ave) en las observaciones de la prueba y seleccionar el método de aprendizaje para el cual la prueba MSE es más pequeña. \n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/83eb62335ea1b1fd9a4928a68d3a9bc4.png\" width=\"75%\">\n",
        "<figcaption>Fig.8 </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "En la imagen de la izquierda de la Figura 8, hemos generado observaciones de (fig 1) con la verdadera $f$ dada por la curva negra. Las curvas naranja, azul y verde ilustran tres posibles estimaciones de $f$ obtenidas utilizando métodos con niveles crecientes de flexibilidad. La línea naranja es el ajuste de regresión lineal, que es relativamente inflexible. Las curvas azul y verde se produjeron utilizando *smoothing splines*, con diferentes niveles de suavidad. Está claro que a medida que aumenta el nivel de flexibilidad, las curvas se ajustan más a los datos observados. La curva verde es la más flexible y coincide muy bien con los datos; sin embargo, observamos que se ajusta mal a la verdadera $f$ (mostrada en negro) porque es demasiado ondulada. Al ajustar el nivel de flexibilidad del ajuste de spline suavizado, podemos producir muchos ajustes diferentes a estos datos.\n",
        "\n",
        "Pasamos ahora al panel de la derecha de la Figura 8. La curva gris muestra el $MSE$ de entrenamiento promedio en función de la flexibilidad, o más formalmente los grados de libertad, para una serie de splines suavizantes. Los grados de libertad son una cantidad que resume la flexibilidad de una curva. Los cuadrados naranja, azul y verde indican las $MSEs$ asociadas con las curvas correspondientes en el panel de la izquierda. Una curva más restringida y, por lo tanto, más suave tiene menos grados de libertad que una curva ondulada.\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/47a6d3a14051a4d7825160c44e1df7f4.png\" width=\"75%\">\n",
        "<figcaption>Fig.9 </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La figura 9 proporciona otro ejemplo en el que la verdadera $f$ es aproximadamente lineal. Nuevamente observamos que el $MSE$ de entrenamiento disminuye monótonamente a medida que aumenta la flexibilidad del modelo, y que hay una forma de U en el $MSE$ de prueba. Sin embargo, debido a que la verdad es casi lineal, la prueba $MSE$ solo disminuye ligeramente antes de aumentar nuevamente, de modo que el ajuste de mínimos cuadrados naranja es sustancialmente mejor que la curva verde altamente flexible. Por último, la figura 10 muestra un ejemplo en el que $f$ es muy no lineal. Las curvas de entrenamiento y prueba de $MSE$ aún exhiben los mismos patrones generales, pero ahora hay una rápida disminución en ambas curvas antes de que la prueba de $MSE$ comience a aumentar lentamente.\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://gyazo.com/ef9b79968fc67fe6f110ec0999b2355a.png\" width=\"75%\">\n",
        "<figcaption>Fig.10 </figcaption>\n",
        "</p>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0E-FfyE-1p7"
      },
      "source": [
        "### La compensación sesgo-varianza\n",
        "\n",
        "La forma de U observada en las curvas MSE anteriores es el resultado de dos propiedades de los métodos de aprendizaje estadístico. Es posible demostrar que el MSE de prueba esperado para un valor $x0$ determinado, puede descomponerse en la suma de tres elementos fundamentales: la varianza de $\\hat{f}(x_0)$, el sesgo cuadrático (*squared bias*) de $\\hat{f}(x_0)$ y la varianza del error en términos de $\\varepsilon$. Es decir,\n",
        "\n",
        "$$E(y_0 - \\hat{f}(x_0))^2 = Var(\\hat{f}(x_0)) + [sesgo(\\hat{f}(x_0))]^2 + Var(\\varepsilon) $$\n",
        "\n",
        "En este sentido, la notación $E(y_0 - \\hat{f}(x_0))^2$ define el *MSE de prueba esperado*, y hace referencia al MSE de prueba promedio que obtendríamos si estimamos $f$ repetidamente utilizando un gran número de conjuntos de entrenamiento, y probando cada una de ellas en $x_0$.\n",
        "\n",
        "La fórmula anterior está relacionada con el compromiso sesgo-varianza. Dicho compromiso refleja el hecho de que cuánto más flexible sea el modelo, la varianza será menor pero el sesgo será mayor, y recírprocamente para modelos menos flexibles. Pero, ¿a qué nos referimos con varianza y sesgo? \n",
        "\n",
        "* La **varianza** se refiere a la cantidad en que $\\hat{f}$ cambiaría si lo estimamos utilizando un conjunto de datos de entrenamiento diferente. Si una técnica tiene una varianza alta, pequeños cambios en el conjunto de entrenamiento pueden suponer cambios importantes en $\\hat{f}$.\n",
        "\n",
        "* El **sesgo** se refiere al error que se introduce aproximando un problema real a un modelo más simple. Por ejemplo, una regresión lineal asume que existe una relación lineal entre  $Y$ y $X_1, X_2, ... , X_p$. \n",
        "\n",
        "Como regla general, a medida que aumenta la flexibilidad de la técnica, aumenta la varianza y disminuye el sesgo. Consecuentemente, la tasa relativa de variabilidad de estas dos cantidades determinan si la prueba MSE aumenta o disminuye. \n",
        "\n",
        "\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/eabe1e5d2299a25fff77ea6bc9674108.png\" width=\"75%\">\n",
        "<figcaption>Fig. 12 </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La relación entre el sesgo, la varianza y el conjunto de validación MSE que se dan en la fórmula anterior  y que se muestra en la figura 2.12 se conoce como el **compromiso de sesgo-varianza**. Un buen rendimiento del conjunto de validación con un método de aprendizaje estadístico requiere una baja varianza y un bajo sesgo. Esto se conoce como un compromiso porque es fácil obtener un método con un sesgo extremadamente bajo, pero alta varianza (por ejemplo, dibujando una curva que pasa por cada observación de entrenamiento) o un método con muy baja varianza pero alto\n",
        "sesgo (ajustando una línea horizontal a los datos). \n",
        "\n",
        "El desafío consiste en encontrar un método para el cual tanto la varianza como el sesgo sean bajos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzijW0XM-9-a"
      },
      "source": [
        "### El ajuste de clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD9MBwjZ2ycw"
      },
      "source": [
        "Hasta ahora, el debate sobre la precisión del modelo ha estado centrado en el ajuste de los problemas de reglesión. No obstante, muchos de los conceptos que hemos visto, como la compensación entre sesgo y varianza, se aplican también al ajuste en ls problemas de clasificación, con solo algunas pequeñas modificaciones debido a que en la clasificación $y_i$ no es un valor numérico. \n",
        "\n",
        "Supongamos que queremos estimar $f$ sobre un conjunto de entrenamiento ${(x_1,y_1), ..., (x_n, y_n)}$, de forma que $y_1, ..., y_n$ son valores cualitativos. El enfoque más común para cuantificar la precisión de nuestra estimación $\\hat{f}$ es la **tasa de error de entrenamiento**, que se define como la proporción de errores que se producen si aplicamos $\\hat{f}$ a las observaciones:\n",
        "\n",
        "$$ \\frac{1}{n}\\sum_{i=1}^{n}I(y_i \\neq \\hat{y}_i)$$\n",
        "\n",
        "Donde $\\hat{y}$ es la clase predicha para la observación i-ésima utilizando $\\hat{f}$. $I(y_i \\neq \\hat{y}_i)$ es una variable que indica que es igual a 1 si $y_i \\neq \\hat{y}_i$ y cero si $I(y_i = \\hat{y}_i)$. En este sentido, si $I(y_i \\neq \\hat{y}_i) = 0$, entonces la observación i-ésima fue clasificada correctamente, y, en caso contrario, se ha clasificado de manera incorrecta. \n",
        "\n",
        "Igual que en la regresión, nos interesan tasas de error procedentes de aplicar el clasificador a las observaciones de prueba que no se han utilizado en el entrenamiento. Así, la **tasa de error** asociada a un conjunto de prueba de la forma (x_0, y_0) viene dada por:\n",
        "\n",
        "$$ Ave(I(y_0 \\neq \\hat{y}_0)) $$\n",
        "\n",
        "donde $\\hat{y_0}$ es la clase predicha como resultado de aplicar el clasificador a la observación de prueba con predictor $x_0$. Cuánto más pequeño sea la tasa de error, mejor será el clasificador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFXaQDjo-98c"
      },
      "source": [
        "#### Clasificador Bayesiano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p45iJ8ZyUxpb"
      },
      "source": [
        "Es posible demostrar que, en general, la tasa de error se reduce utilizando un simple clasificador que asigne cada instancia a la clase más probable, dados sus variables predictoras. En otras palabras, una observación con vector de características $x_0$ se clasifica en la clase $j$ para la cual\n",
        "\n",
        "$$ Pr(Y = j | X = x_0)$$\n",
        "\n",
        "es mayor. La ecuación anterior es una probabilidad condicional: es la probabilidad de que $Y = j$ dado el vector de variables predictoras $x_0$. Este clasificador tan simple se conoce como **clasificador Bayesiano**. En un problema de clasificación binaria, dónde solo hay dos posibles valores de salida, por ejemplo, clase 1 o clase 2, el clasificador Bayesiano clasificará la observación en la clase 1 si $Pr(Y = 1 | X = x_0) > 0.5$, y como clase 2 en caso contrario. \n",
        "\n",
        "La Figura 13, muestra un ejemplo utilizando un dataset con 100 instancias sobre un espacio dimensional con dos variables predictoras $X_1$ y $X_2$. Los círculos naranjas y azules se corresponden con las observaciones que pertenecen a dos clases diferentes. La región sombreada de color naranja refleja el conjunto de puntos para los cuales $Pr(Y = orange|X)$ es mayor que 0.5, mientras que la región azul indica el conjunto de puntos para los cuales la probabilidad es menor que 0.5. La línea de puntos morados representa el límite para el cual la probabilidad es exactamente del 50%, y se conoce como **límite de decisión**. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/17ad9e119b7532d99cd5d16770aaaa11.png\" width=\"35%\">\n",
        "<figcaption>Fig.13 Dataset formado por 100 observaciones divididas en dos grupos: azul y naranja. </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "La predición del clasificador Bayesiano está determinada por el límite de decisión, toda instancia que caiga en el lado naranja se clasificará como clase naranja, y de manera similar, se hará la clasificación en la clase azul. \n",
        "\n",
        "El clasificador Bayesiano produce la menor tasa de error posible, conocida como **tasa de error de Bayes**. Como el clasificador de Bayes siempre elige la clase para la que la probabilidad condicional es mayor, el error en $X = x_0$ será $1 - max_j Pr(Y=j | X=x_0)$. En general, la tasa de error viene dada por:\n",
        "\n",
        "$$1 - E (max_j Pr(Y=j | X)) $$\n",
        "\n",
        "Para nuestros datos simulados, la tasa de error de Bayes es de 0,1304. Es mayor que cero, porque las clases se superponen en la población real, así que $max_j Pr(Y = j|X = x0) < 1$ para algunos valores de $x_0$. La tasa de error de Bayes es análoga al error irreducible, discutido anteriormente.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhNLOaEV-96p"
      },
      "source": [
        "#### K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvabjz_pUyfP"
      },
      "source": [
        "En los problemas reales, no conocemos la distribución condicional de $Y$ dado $X$, por lo que computar el clasificador de Bayes es imposible. Otros muchos enfoques intentan estimar la distribución condicionada de $Y$ dado $X$ y, después, clasificar una observación a la clase con mayor probabilidad estimada. Un clasificador que sigue esta aproximación es el clasificador **K vecinos más cercanos** (*K-nearest neighbors*, KNN).  Dado un número entero positivo $K$, y una observación de prueba $x_0$, el clasificador KNN identifica los K puntos del conjunto de entrenamiento más cercanos a $x_0$, representados por $N_0$. Después, estima la probabilidad condicional de clase $j$ como la fracción de puntos en $N_0$ para los que su respuesta es igual a $j$:\n",
        "\n",
        "$$Pr(Y=j|X=x_0) = \\frac{1}{K} \\sum_{i \\in N_0}I(y_i = j)$$\n",
        "\n",
        "Finalmente, KNN aplica el teorema de Bayes y clasifica la instancia $x_0$ a la clase con mayor probabilidad. \n",
        "\n",
        "En la siguiente figura se muestra un ejemplo del algoritmo KNN. En la parte izquierda, se muestra un pequeño conjunto de datos con seis observaciones azules y seis observaciones naranjas. Nuestro objetivo es clasificar el punto marcado con la x negra suponiendo que elegimos K=3. En este caso, KNN identificará primero las tres instancias más cercanas al punto de la x. Esta vecindad se representa con el círculo verde, y está formada por dos puntos azules y un punto naranja, por lo que las probabilidades estimadas serán de 1/3 para la clase naranja y 2/3 para la clase azul. Así pues, KNN clasificará la x en la clase azul. \n",
        "\n",
        "En el gráfico de la parte derecha, se ha aplicado KNN con K=3 a todos los posibles valores de $X_1$ y $X_2$ para dibujar los límites de decisión del algoritmo en este conjunto de datos. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/b1d7f7920c5cd48a319c25976bd30987.png\" width=\"45%\">\n",
        "<figcaption>Fig.14 Clasificador KNN utilizando K=3. </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "\n",
        "La elección del valor de K tiene un efecto significativo en el clasificador KNN. En la Figura 16, se muestran los límites de decisión para KNN ajustado a los datos de la Figura 13 utilizando K=1 y K=100. Cuando K=1, el límite de decisión busca patrones en los datos que nada tienen que ver con los límites de decisión que construye el clasificador de Bayes. Esto se corresponde con un clasificador que tiene un sesgo bajo y una varianza alta. A medida que K crece, el clasificador se hace menos flexible y produce un límite de decisión cercano a uno lineal. En este caso, se trata de un clasificador con una varianza baja y un sesgo alto. Sin embargo, para este conjunto de datos, ni K = 1 ni K = 100 dan buenas predicciones: tienen tasas de error de prueba de 0,1695 y 0,1925, respectivamente.\n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/e31364bb0cdfe5d925b6509b4ecef11a.png\" width=\"65%\">\n",
        "<figcaption>Fig.16 Comparación de los límites de decisión de KNN utilizando diferentes valores de K para los datos de la Figura 2.13 </figcaption>\n",
        "</p>\n",
        "</center>\n",
        "\n",
        "Al igual que en los problemas  de regresión, no hay una relación estricta entre la tasa de error en el entrenamiento y la tasa de error en la prueba. Con K=1, la tasa de error de KNN es 0, pero la tasa de error en el conjunto de prueba puede ser un poco alta. En general, al utilizar métodos de clasificación más flexibles, el error de entrenamiento disminuye, aunque puede que la tasa de error de la prueba no disminuya\n",
        "\n",
        "En la figura 2.17, se ha trazado las tasas de error de prueba y entrenamiento para  KNN como función de 1/K.  Cuando 1/K aumenta, el clasificador se vuelve más flexible. Al igual que en los problemas de regresión, la tasa de error de entrenamiento disminuye a medida que la flexibilidad del método aumenta. Sin embargo, la tasa de error de prueba muestra una característica forma de U: primero disminuye (con un máximo en aproximadamente K=10), antes de incrementar cuando el algoritmo es demasiado flexible y está sobreajustado. \n",
        "\n",
        "<center>\n",
        "<p>\n",
        "<img src=\"https://i.gyazo.com/c716fc4c2a676d2958a759d71d838258.png\" width=\"55%\">\n",
        "<figcaption>Fig.17 Tasa de error en el conjunto de entrenamiento y conjunto de prueba para KNN, para los datos de la Figura 13 </figcaption>\n",
        "</p>\n",
        "</center>\n"
      ]
    }
  ]
}